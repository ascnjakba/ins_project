{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1602c9fc",
   "metadata": {},
   "source": [
    "# data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ad9caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def read_data_from_csv():\n",
    "    comments=pd.read_csv('comments.csv')\n",
    "    return comments\n",
    "\n",
    "\n",
    "def data_cleaning():\n",
    "    #DO NOT REMOVE FOLLOWING LINE\n",
    "    #call remove_unwanted_columns() function to get dataframe\n",
    "    comments=read_data_from_csv()\n",
    "\n",
    "    #Remove Unwanted columns\n",
    "    \n",
    "    \n",
    "    \n",
    "    #rename columns, only these columns are allowed in the dataset\n",
    "    # 1.\tid\n",
    "    # 2.\tcomment_text\n",
    "    # 3.\tuser_id\n",
    "    # 4.\tphoto_id\n",
    "    # 5.\tcreated_at\n",
    "    \n",
    "    # rename columns\n",
    "    comments.rename(columns={'comment': 'comment_text'}, inplace=True)\n",
    "    comments.rename(columns={'User  id': 'user_id'}, inplace=True)\n",
    "    comments.rename(columns={'Photo id': 'photo_id'}, inplace=True)\n",
    "    comments.rename(columns={'created Timestamp': 'created_at'}, inplace=True)\n",
    "    # drop columns\n",
    "    comments.drop('posted date', axis=1, inplace=True)\n",
    "    comments.drop('emoji used', axis=1, inplace=True)\n",
    "    comments.drop('Hashtags used count', axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    #export cleaned Dataset to newcsv file named \"comments_cleaned.csv\"\n",
    "    comments.to_csv('comments_cleaned.csv', index=False)\n",
    "    return comments\n",
    "\n",
    "\n",
    "#Do not Delete the Following function\n",
    "def task_runner():\n",
    "    data_cleaning()\n",
    "\n",
    "task_runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93985ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def read_data_from_csv():\n",
    "    follows=pd.read_csv('follows.csv')\n",
    "    return follows\n",
    "\n",
    "\n",
    "def data_cleaning():\n",
    "    #DO NOT REMOVE FOLLOWING LINE\n",
    "    #call remove_unwanted_columns() function to get dataframe\n",
    "    follows=read_data_from_csv()\n",
    "\n",
    "    #Remove Unwanted columns\n",
    "    \n",
    "    \n",
    "    \n",
    "    #rename columns, only these columns are allowed in the dataset\n",
    "    # 1.\tfollower_id\n",
    "    # 2.\tfollowee_id\n",
    "    # 3.\tcreated_at\n",
    "    # rename columns\n",
    "    follows.rename(columns={'follower': 'follower_id'}, inplace=True)\n",
    "    follows.rename(columns={'followee ': 'followee_id'}, inplace=True)\n",
    "    follows.rename(columns={'created time': 'created_at'}, inplace=True)\n",
    "    # remove columns\n",
    "    follows.drop('followee Acc status', axis=1, inplace=True)\n",
    "    follows.drop('is follower active', axis=1, inplace=True)\n",
    "    #export cleaned Dataset to newcsv file named \"follows_cleaned.csv\"\n",
    "    follows.to_csv('follows_cleaned.csv',index=False)\n",
    "    return follows\n",
    "\n",
    "\n",
    "#Do not Delete the Following function\n",
    "def task_runner():\n",
    "    data_cleaning()\n",
    "\n",
    "task_runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e77b332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def read_data_from_csv():\n",
    "    likes=pd.read_csv('likes.csv')\n",
    "    return likes\n",
    "\n",
    "\n",
    "def data_cleaning():\n",
    "    #DO NOT REMOVE FOLLOWING LINE\n",
    "    #call remove_unwanted_columns() function to get dataframe\n",
    "    likes=read_data_from_csv()\n",
    "\n",
    "    #Remove Unwanted columns\n",
    "    \n",
    "    \n",
    "    \n",
    "    #rename columns, only these columns are allowed in the dataset\n",
    "    # 1.\tuser_id\n",
    "    # 2.\tphoto_id\n",
    "    # 3.\tcreated_at\n",
    "    # rename columns\n",
    "    likes.rename(columns={'user ': 'user_id'}, inplace=True)\n",
    "    likes.rename(columns={'photo': 'photo_id'}, inplace=True)\n",
    "    likes.rename(columns={'created time': 'created_at'}, inplace=True)\n",
    "    # remove columns\n",
    "    likes.drop('following or not', axis=1, inplace=True)\n",
    "    likes.drop('like type', axis=1, inplace=True)\n",
    "    #export cleaned Dataset to newcsv file named \"likes_cleaned.csv\"\n",
    "    likes.to_csv('likes_cleaned.csv',index=False)\n",
    "    return likes\n",
    "\n",
    "\n",
    "#Do not Delete the Following function\n",
    "def task_runner():\n",
    "    data_cleaning()\n",
    "\n",
    "task_runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72d17234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def read_data_from_csv():\n",
    "    photo_tags=pd.read_csv('photo_tags.csv')\n",
    "    return photo_tags\n",
    "\n",
    "\n",
    "def data_cleaning():\n",
    "    #DO NOT REMOVE FOLLOWING LINE\n",
    "    #call remove_unwanted_columns() function to get dataframe\n",
    "    photo_tags=read_data_from_csv()\n",
    "\n",
    "    #Remove Unwanted columns\n",
    "    \n",
    "    \n",
    "    \n",
    "    #rename columns, only these columns are allowed in the dataset\n",
    "    # 1.\tphoto_id\n",
    "    # 2.\ttag_id\n",
    "    # rename columns\n",
    "    photo_tags.rename(columns={'photo': 'photo_id'}, inplace=True)\n",
    "    photo_tags.rename(columns={'tag ID': 'tag_id'}, inplace=True)\n",
    "    # remove columns\n",
    "    photo_tags.drop('user id', axis=1, inplace=True)\n",
    "    #export cleaned Dataset to newcsv file named \"photo_tags_cleaned.csv\"\n",
    "    photo_tags.to_csv('photo_tags_cleaned.csv', index=False)\n",
    "    return photo_tags\n",
    "\n",
    "\n",
    "#Do not Delete the Following function\n",
    "def task_runner():\n",
    "    data_cleaning()\n",
    "\n",
    "task_runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5c2d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def read_data_from_csv():\n",
    "    photos=pd.read_csv('photos.csv')\n",
    "    return photos\n",
    "\n",
    "\n",
    "def data_cleaning():\n",
    "    #DO NOT REMOVE FOLLOWING LINE\n",
    "    #call remove_unwanted_columns() function to get dataframe\n",
    "    photos=read_data_from_csv()\n",
    "\n",
    "    #Remove Unwanted columns\n",
    "    \n",
    "    \n",
    "    \n",
    "    #rename columns, only these columns are allowed in the dataset\n",
    "    # 1.\tid\n",
    "    # 2.\timage_url\n",
    "    # 3.\tuser_id\n",
    "    # 4.\tcreated_date\n",
    "    # rename columns\n",
    "    photos.rename(columns={'image link': 'image_url'}, inplace=True)\n",
    "    photos.rename(columns={'user ID': 'user_id'}, inplace=True)\n",
    "    photos.rename(columns={'created dat': 'created_date'}, inplace=True)\n",
    "    # remove columns\n",
    "    photos.drop('Insta filter used', axis=1, inplace=True)\n",
    "    photos.drop('photo type', axis=1, inplace=True)\n",
    "    #export cleaned Dataset to newcsv file named \"photos_cleaned.csv\"\n",
    "    photos.to_csv('photos_cleaned.csv', index=False)\n",
    "    return photos\n",
    "\n",
    "\n",
    "#Do not Delete the Following function\n",
    "def task_runner():\n",
    "    data_cleaning()\n",
    "\n",
    "task_runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c575fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def read_data_from_csv():\n",
    "    tags=pd.read_csv('tags.csv')\n",
    "    return tags\n",
    "\n",
    "\n",
    "def data_cleaning():\n",
    "    #DO NOT REMOVE FOLLOWING LINE\n",
    "    #call remove_unwanted_columns() function to get dataframe\n",
    "    tags=read_data_from_csv()\n",
    "\n",
    "    #Remove Unwanted columns\n",
    "    \n",
    "    \n",
    "    \n",
    "    #rename columns, only these columns are allowed in the dataset\n",
    "    # 1.\tid\n",
    "    # 2.\ttag_name\n",
    "    # 3.\tcreated_at\n",
    "    # rename columns\n",
    "    tags.rename(columns={'tag text': 'tag_name'}, inplace=True)\n",
    "    tags.rename(columns={'created time': 'created_at'}, inplace=True)\n",
    "    # remove columns\n",
    "    tags.drop('location', axis=1, inplace=True)\n",
    "    #export cleaned Dataset to newcsv file named \"tags_cleaned.csv\"\n",
    "    tags.to_csv('tags_cleaned.csv', index=False)\n",
    "    return tags\n",
    "\n",
    "\n",
    "#Do not Delete the Following function\n",
    "def task_runner():\n",
    "    data_cleaning()\n",
    "\n",
    "task_runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18d5c307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def read_data_from_csv():\n",
    "    users=pd.read_csv('users.csv')\n",
    "    return users\n",
    "\n",
    "\n",
    "def data_cleaning():\n",
    "    #DO NOT REMOVE FOLLOWING LINE\n",
    "    #call remove_unwanted_columns() function to get dataframe\n",
    "    users=read_data_from_csv()\n",
    "\n",
    "    #Remove Unwanted columns\n",
    "    \n",
    "    \n",
    "    \n",
    "    #rename columns, only these columns are allowed in the dataset\n",
    "    # 1.\tid\n",
    "    # 2.\tusername\n",
    "    # 3.\tcreated_at\n",
    "    # rename columns\n",
    "    users.rename(columns={'name': 'username', 'created time': 'created_at'}, inplace=True)\n",
    "    # remove columns\n",
    "    users.drop('private/public', axis=1, inplace=True)\n",
    "    users.drop('post count', axis=1, inplace=True)\n",
    "    users.drop('Verified status', axis=1, inplace=True)\n",
    "    #export cleaned Dataset to newcsv file named \"users_cleaned.csv\"\n",
    "    users.to_csv('users_cleaned.csv', index=False)\n",
    "    return users\n",
    "\n",
    "\n",
    "#Do not Delete the Following function\n",
    "def task_runner():\n",
    "    data_cleaning()\n",
    "\n",
    "task_runner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80010e48",
   "metadata": {},
   "source": [
    "HOST = 'localhost'\n",
    "USERNAME = 'b11cd57f'\n",
    "PASSWORD = 'Cab#22se'\n",
    "DATABASE = 'b11cd57f'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cdd5c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = 'localhost'\n",
    "USERNAME = 'root'\n",
    "PASSWORD = 'aptx4869'\n",
    "DATABASE = 'b11cd57f'\n",
    "\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# connect to mysql database\n",
    "cnx = mysql.connector.connect(user='root', password='aptx4869',\n",
    "                              host='localhost', database='b11cd57f')\n",
    "cursor = cnx.cursor()\n",
    "\n",
    "# set up table\n",
    "comments_table = '''CREATE TABLE IF NOT EXISTS comments(\n",
    "                        id INT,\n",
    "                        comment_text VARCHAR(255),\n",
    "                        user_id INT,\n",
    "                        photo_id INT,\n",
    "                        created_at DATETIME)'''\n",
    "follows_table = ''' CREATE TABLE IF NOT EXISTS follows(\n",
    "                        follower_id INT,\n",
    "                        followee_id INT,\n",
    "                        created_at DATETIME)'''\n",
    "likes_table = '''CREATE TABLE IF NOT EXISTS likes(\n",
    "                        user_id INT,\n",
    "                        photo_id INT,\n",
    "                        created_at DATETIME)'''\n",
    "photo_tags_table = '''CREATE TABLE IF NOT EXISTS photo_tags(\n",
    "                        photo_id INT,\n",
    "                        tag_id INT)'''\n",
    "photos_table = '''CREATE TABLE IF NOT EXISTS photos(\n",
    "                        id INT,\n",
    "                        image_url VARCHAR(255),\n",
    "                        user_id INT,\n",
    "                        created_date DATETIME)'''\n",
    "tags_table = '''CREATE TABLE IF NOT EXISTS tags(\n",
    "                        id INT,\n",
    "                        tag_name VARCHAR(255) NOT NULL,\n",
    "                        created_at DATETIME)'''\n",
    "users_table = '''CREATE TABLE IF NOT EXISTS users(\n",
    "                        id INT,\n",
    "                        username VARCHAR(255) NOT NULL,\n",
    "                        created_at DATETIME)'''\n",
    "cursor.execute(comments_table)\n",
    "cursor.execute(follows_table)\n",
    "cursor.execute(likes_table)\n",
    "cursor.execute(photo_tags_table)\n",
    "cursor.execute(photos_table)\n",
    "cursor.execute(tags_table)\n",
    "cursor.execute(users_table)\n",
    "\n",
    "cnx.commit()\n",
    "\n",
    "# close connection\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ff58d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "comments = pd.read_csv('comments_cleaned.csv')\n",
    "comments['created_at'] = pd.to_datetime(comments['created_at'], format='%d-%m-%Y %H:%M').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "follows = pd.read_csv('follows_cleaned.csv')\n",
    "follows['created_at'] = pd.to_datetime(follows['created_at'], format='%d-%m-%Y %H:%M').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "likes = pd.read_csv('likes_cleaned.csv')\n",
    "likes['created_at'] = pd.to_datetime(likes['created_at'], format='%d-%m-%Y %H:%M').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "photo_tags = pd.read_csv('photo_tags_cleaned.csv')\n",
    "photos = pd.read_csv('photos_cleaned.csv')\n",
    "photos['created_date'] = pd.to_datetime(photos['created_date'], format='%d-%m-%Y %H:%M').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "tags = pd.read_csv('tags_cleaned.csv')\n",
    "tags['created_at'] = pd.to_datetime(tags['created_at'], format='%d-%m-%Y %H:%M').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "users = pd.read_csv('users_cleaned.csv')\n",
    "users['created_at'] = pd.to_datetime(users['created_at'], format='%d-%m-%Y %H:%M').dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1933f9c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# 建立到 MySQL 数据库的连接\n",
    "engine = create_engine('mysql+mysqlconnector://root:aptx4869@localhost:3306/b11cd57f')\n",
    "\n",
    "# 将数据导入到 MySQL 数据库中\n",
    "comments.to_sql(name='comments', con=engine, if_exists='append', index=False)\n",
    "follows.to_sql(name='follows', con=engine, if_exists='append', index=False)\n",
    "likes.to_sql(name='likes', con=engine, if_exists='append', index=False)\n",
    "photo_tags.to_sql(name='photo_tags', con=engine, if_exists='append', index=False)\n",
    "photos.to_sql(name='photos', con=engine, if_exists='append', index=False)\n",
    "tags.to_sql(name='tags', con=engine, if_exists='append', index=False)\n",
    "users.to_sql(name='users', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88cd4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
